{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Implementation\n",
    "- https://medium.com/p/72865bda430e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ProbabilityVector:\n",
    "    def __init__(self, probabilities: dict):\n",
    "        states = probabilities.keys()\n",
    "        probs  = probabilities.values()\n",
    "        \n",
    "        assert len(states) == len(probs), \"The probabilities must match the states.\"\n",
    "        assert len(states) == len(set(states)), \"The states must be unique.\"\n",
    "        assert abs(sum(probs) - 1.0) < 1e-12, \"Probabilities must sum up to 1.\"\n",
    "        assert len(list(filter(lambda x: 0 <= x <= 1, probs))) == len(probs), \"Probabilities must be numbers from [0, 1] interval.\"\n",
    "        \n",
    "        self.states = sorted(probabilities)\n",
    "        self.values = np.array(list(map(lambda x: \n",
    "            probabilities[x], self.states))).reshape(1, -1)\n",
    "        \n",
    "    @classmethod\n",
    "    def initialize(cls, states: list):\n",
    "        size = len(states)\n",
    "        rand = np.random.rand(size) / (size**2) + 1 / size\n",
    "        rand /= rand.sum(axis=0)\n",
    "        return cls(dict(zip(states, rand)))\n",
    "    \n",
    "    @classmethod\n",
    "    def from_numpy(cls, array: np.ndarray, state: list):\n",
    "        return cls(dict(zip(states, list(array))))\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        return {k:v for k, v in zip(self.states, list(self.values.flatten()))}\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return pd.DataFrame(self.values, columns=self.states, index=['probability'])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({}) = {}.\".format(self.states, self.values)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, ProbabilityVector):\n",
    "            raise NotImplementedError\n",
    "        if (self.states == other.states) and (self.values == other.values).all():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def __getitem__(self, state: str) -> float:\n",
    "        if state not in self.states:\n",
    "            raise ValueError(\"Requesting unknown probability state from vector.\")\n",
    "        index = self.states.index(state)\n",
    "        return float(self.values[0, index])\n",
    "\n",
    "    def __mul__(self, other) -> np.ndarray:\n",
    "        if isinstance(other, ProbabilityVector):\n",
    "            return self.values * other.values\n",
    "        elif isinstance(other, (int, float)):\n",
    "            return self.values * other\n",
    "        else:\n",
    "            NotImplementedError\n",
    "\n",
    "    def __rmul__(self, other) -> np.ndarray:\n",
    "        return self.__mul__(other)\n",
    "\n",
    "    def __matmul__(self, other) -> np.ndarray:\n",
    "        if isinstance(other, ProbabilityMatrix):\n",
    "            return self.values @ other.values\n",
    "\n",
    "    def __truediv__(self, number) -> np.ndarray:\n",
    "        if not isinstance(number, (int, float)):\n",
    "            raise NotImplementedError\n",
    "        x = self.values\n",
    "        return x / number if number != 0 else x / (number + 1e-12)\n",
    "\n",
    "    def argmax(self):\n",
    "        index = self.values.argmax()\n",
    "        return self.states[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilityMatrix:\n",
    "    def __init__(self, prob_vec_dict: dict):\n",
    "        \n",
    "        assert len(prob_vec_dict) > 1, \"The numebr of input probability vector must be greater than one.\"\n",
    "        assert len(set([str(x.states) for x in prob_vec_dict.values()])) == 1, \"All internal states of all the vectors must be indentical.\"\n",
    "        assert len(prob_vec_dict.keys()) == len(set(prob_vec_dict.keys())), \"All observables must be unique.\"\n",
    "\n",
    "        self.states      = sorted(prob_vec_dict)\n",
    "        self.observables = prob_vec_dict[self.states[0]].states\n",
    "        self.values      = np.stack([prob_vec_dict[x].values \\\n",
    "                           for x in self.states]).squeeze() \n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, states: list, observables: list):\n",
    "        size = len(states)\n",
    "        rand = np.random.rand(size, len(observables)) \\\n",
    "             / (size**2) + 1 / size\n",
    "        rand /= rand.sum(axis=1).reshape(-1, 1)\n",
    "        aggr = [dict(zip(observables, rand[i, :])) for i in range(len(states))]\n",
    "        pvec = [ProbabilityVector(x) for x in aggr]\n",
    "        return cls(dict(zip(states, pvec)))\n",
    "\n",
    "    @classmethod\n",
    "    def from_numpy(cls, array: \n",
    "                  np.ndarray, \n",
    "                  states: list, \n",
    "                  observables: list):\n",
    "        p_vecs = [ProbabilityVector(dict(zip(observables, x))) \\\n",
    "                  for x in array]\n",
    "        return cls(dict(zip(states, p_vecs)))\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        return self.df.to_dict()\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return pd.DataFrame(self.values, \n",
    "               columns=self.observables, index=self.states)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"PM {} states: {} -> obs: {}.\".format(\n",
    "            self.values.shape, self.states, self.observables)\n",
    "\n",
    "    def __getitem__(self, observable: str) -> np.ndarray:\n",
    "        if observable not in self.observables:\n",
    "            raise ValueError(\"Requesting unknown probability observable from the matrix.\")\n",
    "        index = self.observables.index(observable)\n",
    "        return self.values[:, index].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "class HiddenMarkovChain:\n",
    "    def __init__(self, T, E, pi):\n",
    "        self.T = T  # transmission matrix A\n",
    "        self.E = E  # emission matrix B\n",
    "        self.pi = pi\n",
    "        self.states = pi.states\n",
    "        self.observables = E.observables\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"HML states: {} -> observables: {}.\".format(\n",
    "            len(self.states), len(self.observables))\n",
    "    \n",
    "    @classmethod\n",
    "    def initialize(cls, states: list, observables: list):\n",
    "        T = ProbabilityMatrix.initialize(states, states)\n",
    "        E = ProbabilityMatrix.initialize(states, observables)\n",
    "        pi = ProbabilityVector.initialize(states)\n",
    "        return cls(T, E, pi)\n",
    "    \n",
    "    def _create_all_chains(self, chain_length):\n",
    "        return list(product(*(self.states,) * chain_length))\n",
    "    \n",
    "    def score(self, observations: list) -> float:\n",
    "        def mul(x, y): return x * y\n",
    "        \n",
    "        score = 0\n",
    "        all_chains = self._create_all_chains(len(observations))\n",
    "        for idx, chain in enumerate(all_chains):\n",
    "            expanded_chain = list(zip(chain, [self.T.states[0]] + list(chain)))\n",
    "            expanded_obser = list(zip(observations, chain))\n",
    "            \n",
    "            p_observations = list(map(lambda x: self.E.df.loc[x[1], x[0]], expanded_obser))\n",
    "            p_hidden_state = list(map(lambda x: self.T.df.loc[x[1], x[0]], expanded_chain))\n",
    "            p_hidden_state[0] = self.pi[chain[0]]\n",
    "            \n",
    "            score += reduce(mul, p_observations) * reduce(mul, p_hidden_state)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovChain_FP(HiddenMarkovChain):\n",
    "    def _alphas(self, observations: list) -> np.ndarray:\n",
    "        alphas = np.zeros((len(observations), len(self.states)))\n",
    "        alphas[0, :] = self.pi.values * self.E[observations[0]].T\n",
    "        for t in range(1, len(observations)):\n",
    "            alphas[t, :] = (alphas[t - 1, :].reshape(1, -1) \n",
    "                         @ self.T.values) * self.E[observations[t]].T\n",
    "        return alphas\n",
    "    \n",
    "    def score(self, observations: list) -> float:\n",
    "        alphas = self._alphas(observations)\n",
    "        return float(alphas[-1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovChain_Simulation(HiddenMarkovChain):\n",
    "    def run(self, length: int) -> (list, list):\n",
    "        assert length >= 0, \"The chain needs to be a non-negative number.\"\n",
    "        s_history = [0] * (length + 1)\n",
    "        o_history = [0] * (length + 1)\n",
    "        \n",
    "        prb = self.pi.values\n",
    "        obs = prb @ self.E.values\n",
    "        s_history[0] = np.random.choice(self.states, p=prb.flatten())\n",
    "        o_history[0] = np.random.choice(self.observables, p=obs.flatten())\n",
    "        \n",
    "        for t in range(1, length + 1):\n",
    "            prb = prb @ self.T.values\n",
    "            obs = prb @ self.E.values\n",
    "            s_history[t] = np.random.choice(self.states, p=prb.flatten())\n",
    "            o_history[t] = np.random.choice(self.observables, p=obs.flatten())\n",
    "        \n",
    "        return o_history, s_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovChain_Uncover(HiddenMarkovChain_Simulation):\n",
    "    def _alphas(self, observations: list) -> np.ndarray:\n",
    "        alphas = np.zeros((len(observations), len(self.states)))\n",
    "        alphas[0, :] = self.pi.values * self.E[observations[0]].T\n",
    "        for t in range(1, len(observations)):\n",
    "            alphas[t, :] = (alphas[t - 1, :].reshape(1, -1) @ self.T.values) \\\n",
    "                         * self.E[observations[t]].T\n",
    "        return alphas\n",
    "    \n",
    "    def _betas(self, observations: list) -> np.ndarray:\n",
    "        betas = np.zeros((len(observations), len(self.states)))\n",
    "        betas[-1, :] = 1\n",
    "        for t in range(len(observations) - 2, -1, -1):\n",
    "            betas[t, :] = (self.T.values @ (self.E[observations[t + 1]] \\\n",
    "                        * betas[t + 1, :].reshape(-1, 1))).reshape(1, -1)\n",
    "        return betas\n",
    "    \n",
    "    def uncover(self, observations: list) -> list:\n",
    "        alphas = self._alphas(observations)\n",
    "        betas = self._betas(observations)\n",
    "        maxargs = (alphas * betas).argmax(axis=1)\n",
    "        return list(map(lambda x: self.states[x], maxargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovLayer(HiddenMarkovChain_Uncover):\n",
    "    def _digammas(self, observations: list) -> np.ndarray:\n",
    "        L, N = len(observations), len(self.states)\n",
    "        digammas = np.zeros((L - 1, N, N))\n",
    "\n",
    "        alphas = self._alphas(observations)\n",
    "        betas = self._betas(observations)\n",
    "        score = self.score(observations)\n",
    "        for t in range(L - 1):\n",
    "            P1 = (alphas[t, :].reshape(-1, 1) * self.T.values)\n",
    "            P2 = self.E[observations[t + 1]].T * betas[t + 1].reshape(1, -1)\n",
    "            digammas[t, :, :] = P1 * P2 / score\n",
    "        return digammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "    def __init__(self, hml: HiddenMarkovLayer):\n",
    "        self.layer = hml\n",
    "        self._score_init = 0\n",
    "        self.score_history = []\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, states: list, observables: list):\n",
    "        layer = HiddenMarkovLayer.initialize(states, observables)\n",
    "        return cls(layer)\n",
    "\n",
    "    def update(self, observations: list) -> float:\n",
    "        alpha = self.layer._alphas(observations)\n",
    "        beta = self.layer._betas(observations)\n",
    "        digamma = self.layer._digammas(observations)\n",
    "        score = alpha[-1].sum()\n",
    "        gamma = alpha * beta / score \n",
    "\n",
    "        L = len(alpha)\n",
    "        obs_idx = [self.layer.observables.index(x) \\\n",
    "                  for x in observations]\n",
    "        capture = np.zeros((L, len(self.layer.states), len(self.layer.observables)))\n",
    "        for t in range(L):\n",
    "            capture[t, :, obs_idx[t]] = 1.0\n",
    "\n",
    "        pi = gamma[0]\n",
    "        T = digamma.sum(axis=0) / gamma[:-1].sum(axis=0).reshape(-1, 1)\n",
    "        E = (capture * gamma[:, :, np.newaxis]).sum(axis=0) / gamma.sum(axis=0).reshape(-1, 1)\n",
    "\n",
    "        self.layer.pi = ProbabilityVector.from_numpy(pi, self.layer.states)\n",
    "        self.layer.T = ProbabilityMatrix.from_numpy(T, self.layer.states, self.layer.states)\n",
    "        self.layer.E = ProbabilityMatrix.from_numpy(E, self.layer.states, self.layer.observables)\n",
    "            \n",
    "        return score\n",
    "\n",
    "    def train(self, observations: list, epochs: int, tol=None):\n",
    "        self._score_init = 0\n",
    "        self.score_history = (epochs + 1) * [0]\n",
    "        early_stopping = isinstance(tol, (int, float))\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            score = self.update(observations)\n",
    "            print(\"Training... epoch = {} out of {}, score = {}.\".format(epoch, epochs, score))\n",
    "            if early_stopping and abs(self._score_init - score) / score < tol:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "            self._score_init = score\n",
    "            self.score_history[epoch] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... epoch = 1 out of 25, score = 0.0013006714785001687.\n",
      "Training... epoch = 2 out of 25, score = 0.005509420540117939.\n",
      "Training... epoch = 3 out of 25, score = 0.005530858882821673.\n",
      "Training... epoch = 4 out of 25, score = 0.005567116674468161.\n",
      "Training... epoch = 5 out of 25, score = 0.005630618250468592.\n",
      "Training... epoch = 6 out of 25, score = 0.005741158382934683.\n",
      "Training... epoch = 7 out of 25, score = 0.0059280441106285015.\n",
      "Training... epoch = 8 out of 25, score = 0.006225866084209232.\n",
      "Training... epoch = 9 out of 25, score = 0.006652847604517528.\n",
      "Training... epoch = 10 out of 25, score = 0.00717178787364084.\n",
      "Training... epoch = 11 out of 25, score = 0.007683641981602105.\n",
      "Training... epoch = 12 out of 25, score = 0.008100845554754063.\n",
      "Training... epoch = 13 out of 25, score = 0.008410987791562213.\n",
      "Training... epoch = 14 out of 25, score = 0.008650795046039236.\n",
      "Training... epoch = 15 out of 25, score = 0.00886102147011807.\n",
      "Training... epoch = 16 out of 25, score = 0.009075097673252734.\n",
      "Training... epoch = 17 out of 25, score = 0.009329951406970974.\n",
      "Training... epoch = 18 out of 25, score = 0.009689333039044718.\n",
      "Training... epoch = 19 out of 25, score = 0.0102878782164159.\n",
      "Training... epoch = 20 out of 25, score = 0.011401019418781367.\n",
      "Training... epoch = 21 out of 25, score = 0.013424786981837838.\n",
      "Training... epoch = 22 out of 25, score = 0.016313511578944926.\n",
      "Training... epoch = 23 out of 25, score = 0.018908648214774778.\n",
      "Training... epoch = 24 out of 25, score = 0.020384565549170907.\n",
      "Training... epoch = 25 out of 25, score = 0.021105139056607214.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "observations = ['3L', '2M', '1S', '3L', '3L', '3L']\n",
    "\n",
    "states = ['1H', '2C']\n",
    "observables = ['1S', '2M', '3L']\n",
    "\n",
    "hml = HiddenMarkovLayer.initialize(states, observables)\n",
    "hmm = HiddenMarkovModel(hml)\n",
    "\n",
    "hmm.train(observations, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfair Casino Problem\n",
    "\n",
    "- consider an unfair casino that:\n",
    "    - most of the time uses a fair 6-sided die where:\n",
    "        - P(1) = P(2) = P(3) = P(4) = P(5) = P(6) = 1/6 = 0.16\n",
    "    - sometimes uses a loaded 6-sided die where:\n",
    "        - P(6) = 0.5\n",
    "        - P(1) = P(2) = P(3) = P(4) = P(5) = 0.1\n",
    "    - before each roll the casino will switch dice with probability:\n",
    "        - P(Fair --> Fair) = 0.95\n",
    "        - P(Fair --> Loaded) = 0.05\n",
    "        - P(Biased --> Loaded) = 0.9\n",
    "        - P(Biased --> Fair) = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "outcomes = '123456'\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, pFL, pLF):\n",
    "        self.emit = list(outcomes)\n",
    "        self.fairProb = [1.0/6] * 6\n",
    "        self.loadProb = [0.1] * 5 + [0.5]\n",
    "        self.tranProb = { 'F':pFL,'L':pLF }\n",
    "                                \n",
    "    def setState(self,which=None):\n",
    "        if which:  self.state = which\n",
    "        else:      self.state = random.choice('FL')\n",
    "    \n",
    "    def rollDice(self):\n",
    "        if self.state == 'F':  L = self.fairProb\n",
    "        else:                  L = self.loadProb\n",
    "        f = random.random()\n",
    "        S = 0\n",
    "        for i in range(len(L)):\n",
    "            S += L[i]\n",
    "            if f < S:  break\n",
    "        return self.emit[i]\n",
    "\n",
    "    def transit(self):\n",
    "        def switch():\n",
    "            if self.state == 'F':  self.state = 'L'\n",
    "            else:                  self.state = 'F'\n",
    "        p = self.tranProb[self.state]\n",
    "        f = random.random()\n",
    "        if f < p:  switch()\n",
    "            \n",
    "    def sequence(self,N=50):\n",
    "        rolls = list()\n",
    "        states = list()\n",
    "        for i in range(N):\n",
    "            rolls.append(self.rollDice())\n",
    "            states.append(self.state)\n",
    "            self.transit()\n",
    "        return ''.join(rolls),''.join(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = '123456'\n",
    "\n",
    "def checkEStats(m):\n",
    "    N = 10000\n",
    "    m.state = 'F'\n",
    "    fairL = [m.rollDice() for i in range(N)]\n",
    "    m.state = 'L'\n",
    "    loadL = [m.rollDice() for i in range(N)]\n",
    "    for o in outcomes:\n",
    "        print (o, '  F',) \n",
    "        print (str(round(fairL.count(o) * 1.0 / N, 3)).ljust(5)),\n",
    "        print    ('  L',) \n",
    "        print (str(round(loadL.count(o) * 1.0 / N, 3)).ljust(5))\n",
    "    print()\n",
    "            \n",
    "def checkTStats(m):\n",
    "    N = 10000\n",
    "    L = list()\n",
    "    for i in range(N):\n",
    "        L.append(m.state)\n",
    "        m.transit()\n",
    "    totalF = L.count('F')\n",
    "    totalL = L.count('L')\n",
    "    D = { 'F':0,'L':0 }\n",
    "    c1 = L[0]\n",
    "    for c2 in L[1:]:\n",
    "        if c1 != c2:  D[c1] += 1\n",
    "        c1 = c2\n",
    "        \n",
    "    print ('F', totalF,) \n",
    "    print (str(round(D['F'] * 1.0 / totalF, 3)).ljust(5))\n",
    "    print ('L', totalL,) \n",
    "    print (str(round(D['L'] * 1.0 / totalL, 3)).ljust(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFFFFFFFFFFFFFFFFLLLLLLLLLLLLFFFFFFFFFFFFFFFFFFLLL\n",
      "13563561163521232266656166163556334655145166214456\n",
      "\n",
      "LLLLLLLLLLLLLFFFFLLFFFFFFFFFFLLLLLLFFFFFFFFFFFFFFF\n",
      "14623666356216255653323364613663166456521253632563\n",
      "\n",
      "1   F\n",
      "0.162\n",
      "  L\n",
      "0.103\n",
      "2   F\n",
      "0.171\n",
      "  L\n",
      "0.103\n",
      "3   F\n",
      "0.165\n",
      "  L\n",
      "0.096\n",
      "4   F\n",
      "0.166\n",
      "  L\n",
      "0.099\n",
      "5   F\n",
      "0.169\n",
      "  L\n",
      "0.093\n",
      "6   F\n",
      "0.167\n",
      "  L\n",
      "0.506\n",
      "\n",
      "F 6855\n",
      "0.048\n",
      "L 3145\n",
      "0.104\n"
     ]
    }
   ],
   "source": [
    "m = Model(pFL=0.05,pLF=0.1)\n",
    "m.setState('F')\n",
    "L = [m.sequence() for i in range(2)]\n",
    "for r,s in L:   print (s + '\\n' + r + '\\n')\n",
    "\n",
    "checkEStats(m)\n",
    "checkTStats(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Unfair Casino Problem\n",
    "- consider an unfair casino that:\n",
    "    - most of the time uses a fair 2-sided coin where:\n",
    "        - P(H) = P(T) = 0.5\n",
    "    - sometimes uses a loaded 2-sided coin where:\n",
    "        - P(H) = 0.75\n",
    "        - P(T) = 0.25\n",
    "    - before each roll the casino will switch dice with probability:\n",
    "        - P(Fair --> Fair) = 0.9\n",
    "        - P(Fair --> Loaded) = 0.1\n",
    "        - P(Biased --> Loaded) = 0.9\n",
    "        - P(Biased --> Fair) = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "outcomes = 'HT'\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, pFL, pLF):\n",
    "        self.emit = list(outcomes)\n",
    "        self.fairProb = [0.5, 0.5]\n",
    "        self.loadProb = [0.75, 0.25]\n",
    "        self.tranProb = { 'F':pFL,'L':pLF }\n",
    "                                \n",
    "    def setState(self,which=None):\n",
    "        if which:  self.state = which\n",
    "        else:      self.state = random.choice('FL')\n",
    "            \n",
    "    def flipCoin(self):\n",
    "        if self.state == 'F':  L = self.fairProb\n",
    "        else:                  L = self.loadProb\n",
    "        f = random.random()\n",
    "        S = 0\n",
    "        for i in range(len(L)):\n",
    "            S += L[i]\n",
    "            if f < S:  break\n",
    "        return self.emit[i]\n",
    "\n",
    "    def transit(self):\n",
    "        def switch():\n",
    "            if self.state == 'F':  self.state = 'L'\n",
    "            else:                  self.state = 'F'\n",
    "        p = self.tranProb[self.state]\n",
    "        f = random.random()\n",
    "        if f < p:  switch()\n",
    "            \n",
    "    def sequence(self,N=50):\n",
    "        rolls = list()\n",
    "        states = list()\n",
    "        for i in range(N):\n",
    "            rolls.append(self.flipCoin())\n",
    "            states.append(self.state)\n",
    "            self.transit()\n",
    "        return ''.join(rolls),''.join(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = 'TH'\n",
    "\n",
    "def checkEStats(m):\n",
    "    N = 10000\n",
    "    m.state = 'F'\n",
    "    fairL = [m.flipCoin() for i in range(N)]\n",
    "    m.state = 'L'\n",
    "    loadL = [m.flipCoin() for i in range(N)]\n",
    "    for o in outcomes:\n",
    "        print (o, '  F',) \n",
    "        print (str(round(fairL.count(o) * 1.0 / N, 3)).ljust(5)),\n",
    "        print    ('  L',) \n",
    "        print (str(round(loadL.count(o) * 1.0 / N, 3)).ljust(5))\n",
    "    print()\n",
    "            \n",
    "def checkTStats(m):\n",
    "    N = 10000\n",
    "    L = list()\n",
    "    for i in range(N):\n",
    "        L.append(m.state)\n",
    "        m.transit()\n",
    "    totalF = L.count('F')\n",
    "    totalL = L.count('L')\n",
    "    D = { 'F':0,'L':0 }\n",
    "    c1 = L[0]\n",
    "    for c2 in L[1:]:\n",
    "        if c1 != c2:  D[c1] += 1\n",
    "        c1 = c2\n",
    "        \n",
    "    print ('F', totalF,) \n",
    "    print (str(round(D['F'] * 1.0 / totalF, 3)).ljust(5))\n",
    "    print ('L', totalL,) \n",
    "    print (str(round(D['L'] * 1.0 / totalL, 3)).ljust(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFFFFFFFLLLLLLFFFFLLLFFFFFFFFFFFFFFFFFFFFFFFLFFFFF\n",
      "THHHTTTHTTTHTTTHTHTHHHHTHTHHHHHTTHHTHTTTTTHHTTHTHT\n",
      "\n",
      "LLLFFFFFFFFFFFFFFFFFFFFFFLLLLFFFFFFFFFFFFFFFFFFFFF\n",
      "TTHTHHHHHTHHHTHHTHTHTTHTHTHTTHTTTHTTHTTHHHTHTTHTHH\n",
      "\n",
      "T   F\n",
      "0.498\n",
      "  L\n",
      "0.752\n",
      "H   F\n",
      "0.502\n",
      "  L\n",
      "0.248\n",
      "\n",
      "F 5101\n",
      "0.094\n",
      "L 4899\n",
      "0.098\n"
     ]
    }
   ],
   "source": [
    "m = Model(pFL=0.1,pLF=0.1)\n",
    "m.setState('F')\n",
    "L = [m.sequence() for i in range(2)]\n",
    "for r,s in L:   print (s + '\\n' + r + '\\n')\n",
    "\n",
    "checkEStats(m)\n",
    "checkTStats(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation sequence:   O =  [0 2 0 2 2 1]\n",
      "Optimal state sequence: S =  [0 0 0 2 2 1]\n",
      "D =\n",
      "[[ 0.4200  0.1008  0.0564  0.0135  0.0033  0.0000]\n",
      " [ 0.0200  0.0000  0.0010  0.0000  0.0000  0.0006]\n",
      " [ 0.0000  0.0336  0.0000  0.0045  0.0022  0.0003]]\n",
      "E =\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 2]\n",
      " [0 2 0 2 2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi(A, C, B, O):\n",
    "    \"\"\"Viterbi algorithm for solving the uncovering problem\n",
    "\n",
    "    Notebook: C5/C5S3_Viterbi.ipynb\n",
    "\n",
    "    Args:\n",
    "        A (np.ndarray): State transition probability matrix of dimension I x I\n",
    "        C (np.ndarray): Initial state distribution  of dimension I\n",
    "        B (np.ndarray): Output probability matrix of dimension I x K\n",
    "        O (np.ndarray): Observation sequence of length N\n",
    "\n",
    "    Returns:\n",
    "        S_opt (np.ndarray): Optimal state sequence of length N\n",
    "        D (np.ndarray): Accumulated probability matrix\n",
    "        E (np.ndarray): Backtracking matrix\n",
    "    \"\"\"\n",
    "    I = A.shape[0]    # Number of states\n",
    "    N = len(O)  # Length of observation sequence\n",
    "\n",
    "    # Initialize D and E matrices\n",
    "    D = np.zeros((I, N))\n",
    "    E = np.zeros((I, N-1)).astype(np.int32)\n",
    "    D[:, 0] = np.multiply(C, B[:, O[0]])\n",
    "\n",
    "    # Compute D and E in a nested loop\n",
    "    for n in range(1, N):\n",
    "        for i in range(I):\n",
    "            temp_product = np.multiply(A[:, i], D[:, n-1])\n",
    "            D[i, n] = np.max(temp_product) * B[i, O[n]]\n",
    "            E[i, n-1] = np.argmax(temp_product)\n",
    "\n",
    "    # Backtracking\n",
    "    S_opt = np.zeros(N).astype(np.int32)\n",
    "    S_opt[-1] = np.argmax(D[:, -1])\n",
    "    for n in range(N-2, -1, -1):\n",
    "        S_opt[n] = E[int(S_opt[n+1]), n]\n",
    "\n",
    "    return S_opt, D, E\n",
    "\n",
    "# Define model parameters\n",
    "A = np.array([[0.8, 0.1, 0.1], \n",
    "              [0.2, 0.7, 0.1], \n",
    "              [0.1, 0.3, 0.6]])\n",
    "\n",
    "C = np.array([0.6, 0.2, 0.2])\n",
    "\n",
    "B = np.array([[0.7, 0.0, 0.3], \n",
    "              [0.1, 0.9, 0.0], \n",
    "              [0.0, 0.2, 0.8]])\n",
    "\n",
    "\n",
    "O = np.array([0, 2, 0, 2, 2, 1]).astype(np.int32)\n",
    "#O = np.array([1]).astype(np.int32)\n",
    "#O = np.array([1, 2, 0, 2, 2, 1]).astype(np.int32)\n",
    "\n",
    "# Apply Viterbi algorithm\n",
    "S_opt, D, E = viterbi(A, C, B, O)\n",
    "#\n",
    "print('Observation sequence:   O = ', O)\n",
    "print('Optimal state sequence: S = ', S_opt)\n",
    "np.set_printoptions(formatter={'float': \"{: 7.4f}\".format})\n",
    "print('D =', D, sep='\\n')\n",
    "np.set_printoptions(formatter={'float': \"{: 7.0f}\".format})\n",
    "print('E =', E, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
